{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#projetos-de-redes-neurais","title":"Projetos de Redes Neurais","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#matheus-aguiar","title":"Matheus Aguiar","text":"<ul> <li> Data - </li> </ul>"},{"location":"data/main/","title":"Roteiro 1","text":"<p>Deadline and Submission</p> <p> 05.sep (friday)</p> <p> Commits until 23:59</p> <p> Individual</p> <p> Submission the GitHub Pages' Link (yes, only the link for pages) via insper.blackboard.com.</p> <p>Activity: Data Preparation and Analysis for Neural Networks</p> <p>This activity is designed to test your skills in generating synthetic datasets, handling real-world data challenges, and preparing data to be fed into neural networks.</p>"},{"location":"data/main/#exercise-1","title":"Exercise 1","text":""},{"location":"data/main/#exploring-class-separability-in-2d","title":"Exploring Class Separability in 2D","text":"<p>Understanding how data is distributed is the first step before designing a network architecture. In this exercise, you will generate and visualize a two-dimensional dataset to explore how data distribution affects the complexity of the decision boundaries a neural network would need to learn.</p>"},{"location":"data/main/#instructions","title":"Instructions","text":"<ol> <li>Generate the Data: Create a synthetic dataset with a total of 400 samples, divided equally among 4 classes (100 samples each). Use a Gaussian distribution to generate the points for each class based on the following parameters:<ul> <li>Class 0: Mean = \\([2, 3]\\), Standard Deviation = \\([0.8, 2.5]\\)</li> <li>Class 1: Mean = \\([5, 6]\\), Standard Deviation = \\([1.2, 1.9]\\)</li> <li>Class 2: Mean = \\([8, 1]\\), Standard Deviation = \\([0.9, 0.9]\\)</li> <li>Class 3: Mean = \\([15, 4]\\), Standard Deviation = \\([0.5, 2.0]\\)</li> </ul> </li> <li>Plot the Data: Create a 2D scatter plot showing all the data points. Use a different color for each class to make them distinguishable.</li> <li>Analyze and Draw Boundaries:<ol> <li>Examine the scatter plot carefully. Describe the distribution and overlap of the four classes.</li> <li>Based on your visual inspection, could a simple, linear boundary separate all classes?</li> <li>On your plot, sketch the decision boundaries that you think a trained neural network might learn to separate these classes.</li> </ol> </li> </ol>"},{"location":"data/main/#answer","title":"Answer:","text":"<p>Data generation and plot:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Random seed for reproducibility\nnp.random.seed(42)\n\n# Parameters\nmeans = [(0, 0), (3, 0), (0, 3), (3, 3)]\nstds = [0.5, 0.5, 0.5, 0.5]\nn_samples = 100\n\n# Generate data\ndata = []\nlabels = []\nfor i, (mean, std) in enumerate(zip(means, stds)):\n    x = np.random.normal(loc=mean[0], scale=std, size=n_samples)\n    y = np.random.normal(loc=mean[1], scale=std, size=n_samples)\n    data.append(np.column_stack((x, y)))\n    labels.append(np.full(n_samples, i))\n\nX = np.vstack(data)\ny = np.concatenate(labels)\n\n# Plot data\nplt.figure(figsize=(6, 6))\nfor i in range(4):\n    plt.scatter(X[y == i, 0], X[y == i, 1], label=f'Class {i}', alpha=0.7)\nplt.legend()\nplt.title(\"Synthetic 2D Dataset with 4 Classes\")\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.show()\n</code></pre> <p></p> <p>Analysis:</p> <p>Distribution of the points The dataset has four clear clusters in the 2D space. Each cluster represents one class, with 100 samples each. The points are compact and concentrated around different centers:</p> <ul> <li> <p>Class 0 (blue): bottom-left area.</p> </li> <li> <p>Class 1 (orange): bottom-right area.</p> </li> <li> <p>Class 2 (green): top-left area.</p> </li> <li> <p>Class 3 (red): top-right area.</p> </li> </ul> <p>There is almost no overlap between the classes, which makes the separation easier.</p>"},{"location":"data/main/#separability","title":"Separability","text":"<p>In this case, the classes are linearly separable. A vertical line (around x = 1.5) could separate the left classes (0 and 2) from the right classes (1 and 3). A horizontal line (around y = 1.5) could separate the bottom classes (0 and 1) from the top classes (2 and 3). With these two simple boundaries, we can isolate the four regions.</p>"},{"location":"data/main/#decision-boundaries-from-a-neural-network","title":"Decision boundaries from a neural network","text":"<p>If we train a neural network on this dataset, it would probably learn straight boundaries, close to vertical and horizontal lines. This happens because the clusters are well-formed and symmetric. The decision regions would look like four quadrants, each one corresponding to a class.</p>"},{"location":"data/main/#exercise-2","title":"Exercise 2","text":""},{"location":"data/main/#non-linearity-in-higher-dimensions","title":"Non-Linearity in Higher Dimensions","text":"<p>Simple neural networks (like a Perceptron) can only learn linear boundaries. Deep networks excel when data is not linearly separable. This exercise challenges you to create and visualize such a dataset.</p>"},{"location":"data/main/#instructions_1","title":"Instructions","text":"<ol> <li> <p>Generate the Data: Create a dataset with 500 samples for Class A and 500 samples for Class B. Use a multivariate normal distribution with the following parameters:</p> <ul> <li> <p>Class A:</p> <p>Mean vector:</p> \\[\\mu_A = [0, 0, 0, 0, 0]\\] <p>Covariance matrix:</p> \\[ \\Sigma_A = \\begin{pmatrix} 1.0 &amp; 0.8 &amp; 0.1 &amp; 0.0 &amp; 0.0 \\\\ 0.8 &amp; 1.0 &amp; 0.3 &amp; 0.0 &amp; 0.0 \\\\ 0.1 &amp; 0.3 &amp; 1.0 &amp; 0.5 &amp; 0.0 \\\\ 0.0 &amp; 0.0 &amp; 0.5 &amp; 1.0 &amp; 0.2 \\\\ 0.0 &amp; 0.0 &amp; 0.0 &amp; 0.2 &amp; 1.0 \\end{pmatrix} \\] </li> <li> <p>Class B:</p> <p>Mean vector:</p> \\[\\mu_B = [1.5, 1.5, 1.5, 1.5, 1.5]\\] <p>Covariance matrix:</p> \\[ \\Sigma_B = \\begin{pmatrix} 1.5 &amp; -0.7 &amp; 0.2 &amp; 0.0 &amp; 0.0 \\\\ -0.7 &amp; 1.5 &amp; 0.4 &amp; 0.0 &amp; 0.0 \\\\ 0.2 &amp; 0.4 &amp; 1.5 &amp; 0.6 &amp; 0.0 \\\\ 0.0 &amp; 0.0 &amp; 0.6 &amp; 1.5 &amp; 0.3 \\\\ 0.0 &amp; 0.0 &amp; 0.0 &amp; 0.3 &amp; 1.5 \\end{pmatrix} \\] </li> </ul> </li> <li> <p>Visualize the Data: Since you cannot directly plot a 5D graph, you must reduce its dimensionality.</p> <ul> <li>Use a technique like Principal Component Analysis (PCA) to project the 5D data down to 2 dimensions.</li> <li>Create a scatter plot of this 2D representation, coloring the points by their class (A or B).</li> </ul> </li> <li>Analyze the Plots:<ol> <li>Based on your 2D projection, describe the relationship between the two classes.</li> <li>Discuss the linear separability of the data. Explain why this type of data structure poses a challenge for simple linear models and would likely require a multi-layer neural network with non-linear activation functions to be classified accurately.</li> </ol> </li> </ol>"},{"location":"data/main/#answer_1","title":"Answer:","text":"<p>Data generation, PCA, and plot:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Passo 1: Definir os par\u00e2metros para as distribui\u00e7\u00f5es\nmu_A = np.array([0, 0, 0, 0, 0])\nsigma_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n])\n\nmu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\nsigma_B = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n])\n\n# Passo 2: Gerar os dados\nnum_samples = 500\nclass_A = np.random.multivariate_normal(mu_A, sigma_A, num_samples)\nclass_B = np.random.multivariate_normal(mu_B, sigma_B, num_samples)\n\n# Combinar os dados e r\u00f3tulos\nX = np.vstack((class_A, class_B))\ny = np.hstack((np.zeros(num_samples), np.ones(num_samples)))\n\n# Passo 3: Reduzir dimensionalidade com PCA (implementa\u00e7\u00e3o manual)\n# Centralizar os dados\nX_mean = np.mean(X, axis=0)\nX_centered = X - X_mean\n\n# Calcular a matriz de covari\u00e2ncia\ncov_matrix = np.cov(X_centered.T)\n\n# Calcular autovalores e autovetores\neigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n\n# Ordenar autovalores em ordem decrescente\nidx = np.argsort(eigenvalues)[::-1]\ntop_eigenvectors = eigenvectors[:, idx[:2]]  # Selecionar os 2 principais autovetores\n\n# Projetar os dados para 2D\nX_2d = X_centered @ top_eigenvectors\n\n# Passo 4: Visualizar os dados em 2D\nplt.figure(figsize=(8, 6))\nplt.scatter(X_2d[:num_samples, 0], X_2d[:num_samples, 1], c='blue', label='Class A', alpha=0.6)\nplt.scatter(X_2d[num_samples:, 0], X_2d[num_samples:, 1], c='red', label='Class B', alpha=0.6)\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('Proje\u00e7\u00e3o 2D dos Dados usando PCA')\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre> <p></p> <p>Analysis:</p> <p>The data is not linearly separable, meaning that it is not possible to draw a hyperplane (line in 2D, plane in higher dimensions) that perfectly divides the classes without significant errors. In the 2D projection, you will see that a straight line cannot separate blue from red without cutting through many points of one class.</p> <p>This non-linear relationship is a challenge for simple linear models like logistic regression or a single-layer perceptron, which can only learn linear decision boundaries. These models would struggle to classify the data accurately, leading to high error rates.</p>"},{"location":"data/main/#exercise-3","title":"Exercise 3","text":""},{"location":"data/main/#preparing-real-world-data-for-a-neural-network","title":"Preparing Real-World Data for a Neural Network","text":"<p>This exercise uses a real dataset from Kaggle. Your task is to perform the necessary preprocessing to make it suitable for a neural network that uses the hyperbolic tangent (<code>tanh</code>) activation function in its hidden layers.</p>"},{"location":"data/main/#instructions_2","title":"Instructions","text":"<ol> <li>Get the Data: Download the Spaceship Titanic dataset from Kaggle.</li> <li>Describe the Data:<ul> <li>Briefly describe the dataset's objective (i.e., what does the <code>Transported</code> column represent?).</li> <li>List the features and identify which are numerical (e.g., <code>Age</code>, <code>RoomService</code>) and which are categorical (e.g., <code>HomePlanet</code>, <code>Destination</code>).</li> <li>Investigate the dataset for missing values. Which columns have them, and how many?</li> </ul> </li> <li>Preprocess the Data: Your goal is to clean and transform the data so it can be fed into a neural network. The <code>tanh</code> activation function produces outputs in the range <code>[-1, 1]</code>, so your input data should be scaled appropriately for stable training.<ul> <li>Handle Missing Data: Devise and implement a strategy to handle the missing values in all the affected columns. Justify your choices.</li> <li>Encode Categorical Features: Convert categorical columns like <code>HomePlanet</code>, <code>CryoSleep</code>, and <code>Destination</code> into a numerical format. One-hot encoding is a good choice.</li> <li>Normalize/Standardize Numerical Features: Scale the numerical columns (e.g., <code>Age</code>, <code>RoomService</code>, etc.). Since the <code>tanh</code> activation function is centered at zero and outputs values in <code>[-1, 1]</code>, Standardization (to mean 0, std 1) or Normalization to a <code>[-1, 1]</code> range are excellent choices. Implement one and explain why it is a good practice for training neural networks with this activation function.</li> </ul> </li> <li>Visualize the Results:<ul> <li>Create histograms for one or two numerical features (like <code>FoodCourt</code> or <code>Age</code>) before and after scaling to show the effect of your transformation.</li> </ul> </li> </ol> <p>Answer:</p> <p>The spaceship Titanic dataset contains information about passengers on a fictional spaceship. The objective is to predict whether a passenger was transported to another dimension (the <code>Transported</code> column) based on various features such as demographics, travel details, and spending on amenities.</p> <p>Data Description: There are 13 features in the dataset excluding the target variable <code>Transported</code>:</p> <ul> <li>Numerical Features: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code></li> <li>Categorical Features: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code>, <code>Cabin``Transported</code></li> <li>Missing Values: Several columns have missing values, including <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>, <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, and <code>Cabin</code>.</li> </ul> <p>Data Preprocessing Steps:</p> <p>Categorical features filled based on the most common values in the dataset. Numerical features filled with median values to mitigate the effect of outliers. Categorical features encoded using one-hot encoding. Numerical features normalized to the range [-1, 1].</p> <p>note: Handled <code>Cabin</code> by splitting it into <code>deck</code>, <code>num</code>, and <code>side</code>, then filling missing values with the mode.</p> <p>converted <code>Transported</code> to binary (0 and 1).</p> <p>Data Preprocessing:</p> <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Step 1: Load the dataset\n# Note: Replace 'train.csv' with the path to your downloaded Kaggle dataset\ndata = pd.read_csv('train.csv')\n\n# Step 2: Describe the dataset\nprint(\"Dataset Description:\")\nprint(\"Objective: Predict whether a passenger was transported to an alternate dimension (Transported: True/False).\")\nprint(\"\\nFeatures and their types:\")\nprint(data.dtypes)\nprint(\"\\nMissing Values:\")\nprint(data.isnull().sum())\n\n# Step 3: Preprocess the data\n# Handle missing values\n# Numerical columns: Fill with median for robustness to outliers\nnumerical_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\nfor col in numerical_cols:\n    data[col].fillna(data[col].median(), inplace=True)\n\n# Categorical columns: Fill with mode based on predominance\ndata['HomePlanet'] = data['HomePlanet'].fillna('Earth')  # 54% of data\ndata['CryoSleep'] = data['CryoSleep'].fillna(False)     # 64% False\ndata['Destination'] = data['Destination'].fillna('TRAPPIST-1e')  # 69% of data\ndata['VIP'] = data['VIP'].fillna(False)                 # 97% False\n\n# Handle Cabin: Split into deck, num, side, and fill missing with mode\ndata[['cabin_deck', 'cabin_num', 'cabin_side']] = data['Cabin'].str.split('/', expand=True)\ndata['cabin_deck'] = data['cabin_deck'].fillna(data['cabin_deck'].mode()[0])\ndata['cabin_num'] = data['cabin_num'].fillna(data['cabin_num'].mode()[0])\ndata['cabin_side'] = data['cabin_side'].fillna(data['cabin_side'].mode()[0])\ndata = data.drop(columns=['Cabin'])\n\n# Drop irrelevant columns\ndata = data.drop(['PassengerId', 'Name'], axis=1)\n\n# Encode categorical features\ndata = pd.get_dummies(data, columns=['HomePlanet', 'Destination', 'cabin_deck', 'cabin_side'], drop_first=True)\ndata['CryoSleep'] = data['CryoSleep'].astype(int)\ndata['VIP'] = data['VIP'].astype(int)\n\n# Convert cabin_num to numeric, fill any remaining NaN with median\ndata['cabin_num'] = pd.to_numeric(data['cabin_num'], errors='coerce')\ndata['cabin_num'].fillna(data['cabin_num'].median(), inplace=True)\n\n# Convert Transported to binary\ndata['Transported'] = data['Transported'].astype(int)\n\n# Normalize numerical features to [-1, 1] for tanh activation\ndef custom_minmax_scaler(data, cols, feature_range=(-1, 1)):\n    data_scaled = data.copy()\n    for col in cols:\n        min_val = data[col].min()\n        max_val = data[col].max()\n        if max_val != min_val:  # Avoid division by zero\n            data_scaled[col] = (data[col] - min_val) / (max_val - min_val) * (feature_range[1] - feature_range[0]) + feature_range[0]\n        else:\n            data_scaled[col] = 0  # If all values are the same, set to 0\n    return data_scaled\n\ndata_normalized = custom_minmax_scaler(data, numerical_cols + ['cabin_num'])\n\n# Step 4: Visualize numerical features before and after scaling\ndata_original = pd.read_csv('train.csv')  # For comparison\ncolunas_para_visualizar = numerical_cols\n\nfig, axes = plt.subplots(nrows=len(colunas_para_visualizar), ncols=2, figsize=(12, 18))\nfig.suptitle('Histograms Before and After Normalization to [-1, 1]', fontsize=16)\n\nfor i, col in enumerate(colunas_para_visualizar):\n    # Before normalization\n    axes[i, 0].hist(data_original[col].dropna(), bins=30, color='skyblue', edgecolor='black')\n    axes[i, 0].set_title(f'{col} (Before Normalization)')\n    axes[i, 0].set_xlabel('Original Value')\n    axes[i, 0].set_ylabel('Frequency')\n\n    # After normalization\n    axes[i, 1].hist(data_normalized[col], bins=30, color='salmon', edgecolor='black')\n    axes[i, 1].set_title(f'{col} (After Normalization)')\n    axes[i, 1].set_xlabel('Normalized Value [-1, 1]')\n    axes[i, 1].set_ylabel('Frequency')\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n\n# Save the preprocessed dataset\ndata_normalized.to_csv('preprocessed_spaceship_titanic_improved.csv', index=False)\nprint(\"\\nPreprocessed dataset saved as 'preprocessed_spaceship_titanic_improved.csv'\")\n</code></pre> <p></p>"},{"location":"roteiro1/main/","title":"Main","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro1/main/#app","title":"App","text":""},{"location":"roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro2/main/","title":"Main","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Main","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/main/","title":"Main","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-09-07T20:39:32.613889 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ 2025-09-07T20:39:35.528216 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"thisdocumentation/main/","title":"Main","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}